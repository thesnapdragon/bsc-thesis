\chapter{Értékelés, továbbfejlesztési lehetőségek}
\label{cha:ending}

A feladatkiírásban specifikált követelményeknek megfelelően elkészítettem a rendszert:

\begin{itemize}
	\item Áttekintettem az elérhető részben struktúrált tudásbázisokat, mint például a Wikipédiát feldolgozó megoldásokat.
	\item Ismertettem az OSGi rendszer felépítését, legfontosabb tulajdonságait és használatát. Bemutatásra kerültek az OSGi keretrendszerrel való fejlesztéshez használható eszközök, mint például a gosh szkriptek, és az Apache Felix program.
	\item Elkészítettem OSGi komponens formájában egy IRC botot, mely a Wikipédia változásairól folyamatosan értesül, így folyamatos bemenetet szolgáltat az on-the-fly feldolgozáshoz.
	\item Elkészítettem OSGi komponens formájában egy MediaWiki Parsoid parsert használó többszálú megoldást, mely a Parsoid eredeti sebességének többszörösére képes és cluster-t létrehozva a parserekből egy jól skálázható, használható megoldás keletkezett.
	\item Integráltam az MTA SZTAKI által készített teszt kutatómodult, melynek könnyű beépítése is szemlélteti a rendszer könnyen továbbfejleszthetőségét, kiegészíthetőségét.
	\item Teszteltem a rendszer képességeit, funkcionalitását egy méréssel, úgy hogy az on-the-fly feldolgozás és egy teljes Wikipédia dump feldolgozása is el lett indítva.
\end{itemize}

A tesztelés és a mérések során arra jutottam, hogy az elkészített feldolgozólánc képes ellátni azokat a feladatokat, és teljesíti a meghatározott követelményeket, melyek a rendszer tervezése előtt célul lettek kitűzve. Az elkészített alkalmazás úgy lett megtervezve, hogy a korábbi megoldások hiányosságait próbálja pótolni és az on-the-fly feldolgozás miatt hiánypótló is lehet a részben struktúrált adatforrást feldolgozó rendszerek között.

A hasonló megoldások vizsgálatánál láttuk, hogy egy Wikipédiához hasonló mennyiségű adathalmaz feldolgozása semmilyen esetben sem triviális, a használható feldolgozáshoz idő és számítási kapacitás szükséges. A teszteléskor rendelkezésemre álló erőforrások elegendőek voltak a funkcionalitás ellenőrzéséhez, de számítási kapacitásuk a használhatóságot nem érte el. Korábbi vizsgálatok azonban azt mutatták, hogy a rendszer lineárisan skálázódik, így több erőforrás alkalmazásával a feldolgozólánc minden előnyét ki lehet használni.

A rendszer az OSGi keretrendszer előnyeit teljes mértékben kihasználja, a különböző feladatot ellátó komponensek, a WikiBot, Parser és a DBConnector csatolása rendkívül kicsi és azok könnyen menedzselhetőek. Felhasználhatóság szempontjából sokat javított a komponensek funkcionalitásán a felügyeletre tervezés implementálása, a Logger és Statistics komponensek elkészítése.

A SZTAKI által készített elemző kódok integrálása a rendszerbe nagyon könnyű feladat volt. Ez is mutatja, hogy a komponensek jól lettek megtervezve, újabb, más funkcionalitással rendelkező komponens integrálása a rendszerbe sem lenne túl nagy feladat. Remélhetőleg más kutató modulok beépítésére is sor kerül a jövőben, és hasznos segítsége lehet a kutatásoknak a WikiProcessor feldolgozólánc. További kiegészítések és továbbfejlesztési lehetőségek lehetőségeit a következő pontokban foglalom össze.

\begin{description}
	\item[Parser komponens hálózati művelet nélkül]

A mérés során láttuk, hogy a rendszer rendkívül sokat vár hálózati kommunikációra. Egy ilyen nagy teljesítményű rendszernél ez hátrányosan befolyásolja a működést, így érdemes lenne a rendszer leglassabb részét a Parsoid parsert beépíteni a feldolgozóláncba, illetve a hálózati kommunikációt minél jobban kikerülni. Ehhez egyrészt a ParsoidWorker-eket a WikiHarvester géppel azonos gépre kell költöztetni, de hálózati kommunikáció megszűntével elért gyorsítás miatt valószínűleg kevesebb példány futtatása is elegendő lenne.

A kommunikáció azonban a NodeJS-ben írt Parsoid és az OSGi platform között nem egyszerű feladat, így több alternatívát is érdemes lesz kipróbálni. A különböző technológiát használó alkalmazások kommunikációjára egy lehetséges megoldás lehet az interprocessz kommunikáció (\textit{IPC}), amelyet mindkét nyelvből natív módon is el lehet érni, például \textit{MessageQueue} használatával. Másik lehetőség lehet a NodeJS C++-ban implementált V8 JavaScript motorja és az OSGi közötti kommunikáció \textit{JNI} segítségével. A NodeJS-hez létezik is már JNI wrapper a Java API-hoz, így a kommunikáció megoldható lenne, ennek a modulnak a segítségével.

    \item[Feldolgozóláncok készítése egyszerűbben, illetve dinamikusan]

Az eredeti feldolgozólánc architektúrája, melyben nem szerepelt még a dumpfeldolgozás, nagyon egyszerű és átlátható volt, így a célnak megfelelt. A jó tervezésnek köszönhetően a dump feldolgozás is csak két meglévő osztály példányosítását és egy a feladatot végző rész implementációját igényelte. Ebben a helyzetben még mindig elég egyszerű és átlátható a rendszer működése, de látható, hogy az ilyen jellegű kiegészítések szempontjából nem skálázódik egy idő után túl jól a rendszer. Újabb feldolgozási láncok kialakítására a jelenlegiek mellett tehát egyre nehezebbé válik. Ennek a problémának a megoldása lehet, ezen feldolgozóláncok létrehozásának általánosítása.
    
Egyik lehetőség lehet az \textit{Apache Stanbol} \cite{stanbol} nyíltforráskódú és moduláris szoftver stack kiegészítése az eddig elkészített feldolgozólánccal, mely az Apache Stanbol részeként használhatná az teljes software stack egyes komponenseit. Az Apache Stanbol szintén Apache Felix-et használ OSGi futtatókörnyezetként, így ilyen szempontból nem lenne bonyolult a megoldás kivitelezése. A feldolgozóláncok dinamikus előállítása a Stanbol-ban elérhető \textit{Enhancement Chain}-ek segítségével válna elérhetővé. Ennek a megoldásnak a hátránya, hogy az Apache Stanbol funkcióit nem egészítené ki a feldolgozólánc, hanem inkább csak használna azokból néhányat.
    
A fent felsorolt okok miatt érdemes lehet, saját implementációt készíteni a feldolgozóláncok készítéséhez, könnyen kiegészíthető és továbbfejleszthető architektúrával. Ilyen problémák megoldására készült az \textit{Apache Commons Chain} \cite{commonschain} implementációja, mely a \textit{Chain of Responsibility} és \textit{Command} tervezési minta kombinációja.
    
A Chain of Responsibility minta alapgondolata az, hogy szétválasztja a kérést küldõket a fogadóktól azáltal, hogy több objektumnak adja meg a lehetõséget a kérés lekezelésére. A kérés egy objektumokból álló lánc láncszemeit járja be egészen addig, amíg valamelyik láncszem le nem kezeli.
    
A Command minta parancsok, kérések objektumba ágyazását, és ezen keresztül feladatok delegálását fogalmazza meg. Különféle parancsokat rendelhetünk így klienseinkhez (akár dinamikusan is), a parancsokokat akár sorba is állíthatjuk, naplózhatjuk, illetve segítségével visszavonható műveleteket kezelhetünk.
    
    \item[Feldolgozólánc perzisztenciája]

A jelenlegi rendszer leállásával a működéssel kapcsolatos több információ is elveszik azokban a komponensekben, melyek működése nem állapotmentes. Az egyik ilyen kiegészítés lehetne, hogy ha már egyszer feldolgozott a rendszer indulás után egy teljes Wikipédia dump-ot, egy következő indításnál nem érdemes még egyszer megtenni azt.

Leállításkor lehetőség van az OSGi komponensekben az aktuális futás közben használt információk elmentésére az adatbázisban. Például a QueueManager példányokban tárolt információkat ilyenkor lehetne elmenteni, vagy a Statistics komponens által készített statisztikák eltárolását is ekkor kellene megoldani.
\end{description}

Az elvégzett feladat során folyamatosan újabb és újabb technológiákat ismertem meg, ezekben sikerült kellőképpen elmélyedni, így azt hiszem rengeteget tanultam az elvégzett munka alatt. Ezen kívül sikerült egy olyan szoftverrendszer teljes életciklusát végigkövetni és megvalósítani, mely megfelel a kitűzött céloknak és egy használható keretrendszert nyújt azok számára, akik egy ilyen hatalmas tudásbázist akarnak egyszerűen felhasználni, mint a Wikipédia.

% chapter ending (end)